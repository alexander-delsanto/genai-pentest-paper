from genai.llm import LLMClient
from genai.agent import AutonomousAgent
from genai.prompts import INSTRUCTION_TEMPLATE
from genai.working_memory import ReActScratchpad
from agentquest.utils import load_data, Action
from agentquest.drivers.autopenbench import AutoPenBenchDriver
from autopenbench.tools import ExecuteBash, SSHConnect, FinalAnswer
from autopenbench.utils import load_milestones
from autopenbench.evaluation import Evaluator

import os
# Load the OpenAI key
from dotenv import load_dotenv
load_dotenv()
OPENAI_KEY = os.environ.get('OPENAI_KEY')

EPOCHS = 30  # Step budget
LEVEL, CATEGORY, i = 'in-vitro', 'access_control', 0
MODEL = 'o1-preview-2024-09-12'
MNAME = '-'.join(MODEL.split('-')[:2])

for j in range(5):
    # Load the task
    game = load_data(LEVEL)[CATEGORY][i]

    # Load the milestones
    command_milestones = load_milestones('command', LEVEL, CATEGORY, i)
    stage_milestones = load_milestones('stage', LEVEL, CATEGORY, i)

    # Instantiate the agent evaluator
    evaluator = Evaluator(OPENAI_KEY, command_milestones, stage_milestones)

    # Initialize the Tools
    tools = [ExecuteBash, SSHConnect, FinalAnswer]

    # Initialize LLM
    llm = LLMClient(
        api_key=OPENAI_KEY,
        model=MODEL
    )

    # Initialize the WorkingMemory
    working_memory = ReActScratchpad()

    # Initialize the Agent
    agent = AutonomousAgent(
        prompt_template=INSTRUCTION_TEMPLATE,
        llm=llm,
        working_memory=working_memory,
        tools=tools,
        logpath=f'logs/experiments/{MNAME}_run{j}'
    )

    # Initialize the driver
    driver = AutoPenBenchDriver(game)

    # Reset the driver and the agent
    observation = driver.reset()  # Get the first observation
    agent.reset(task=observation.output)  # Reset the agent

    # Run the interaction loop
    epochs = 1
    print(f'Observation: {observation.output}')
    while not observation.done and epochs <= EPOCHS:
        print(f'\n=== Step {epochs} ===')

        # Agent step
        agent_out = agent.step(observation.output)

        # Environment step
        action = Action(agent_out.action)
        observation = driver.step(action)
        print(f'Observation: {observation.output}')

        # Evaluate the current step
        step = f'Action:{agent_out.action}\nObservation: {observation.output}'
        evaluator.evaluate_step(step)

        epochs += 1
    agent.agent_finish(observation.output)
