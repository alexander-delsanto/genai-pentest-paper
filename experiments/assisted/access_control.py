from genai.llm import LLMClient
from genai.agent import AssistedAgent
from genai.prompts import INSTRUCTION_TEMPLATE
from genai.working_memory import ReActScratchpad, ReActChain
from agentquest.utils import load_data, Action
from agentquest.drivers.autopenbench import AutoPenBenchDriver
from autopenbench.tools import ExecuteBash, SSHConnect, FinalAnswer
from autopenbench.utils import load_milestones
from autopenbench.evaluation import Evaluator

import os
# Load the OpenAI API key
from dotenv import load_dotenv
load_dotenv()
OPENAI_KEY = os.environ.get('OPENAI_KEY')

EPOCHS = 30  # Step budget
LEVEL, CATEGORY = 'in-vitro', 'access_control'

for i in range(5):
    # Load the task
    game = load_data(LEVEL)[CATEGORY][i]

    # Load the milestones
    command_milestones = load_milestones('command', LEVEL, CATEGORY, i)
    stage_milestones = load_milestones('stage', LEVEL, CATEGORY, i)

    # Instantiate the agent evaluator
    evaluator = Evaluator(OPENAI_KEY, command_milestones, stage_milestones)

    # Initialize the Tools
    tools = [ExecuteBash, SSHConnect, FinalAnswer]

    # Initialize LLM
    llm = LLMClient(
        api_key=OPENAI_KEY,
        model='gpt-4o-2024-08-06'
    )

    # Initialize the WorkingMemory
    working_memory = ReActScratchpad()

    # Initialize the Agent
    agent = AssistedAgent(
        prompt_template=INSTRUCTION_TEMPLATE,
        llm=llm,
        working_memory=working_memory,
        tools=tools,
        logpath=f'logs/experiments/assisted_{game["target"]}'
    )

    # Initialize the driver
    driver = AutoPenBenchDriver(game)

    # Reset the driver and the agent
    observation = driver.reset()  # Get the first observation
    agent.reset()  # Reset the agent

    # Run the interaction loop
    epochs = 1
    print(f'Observation: {observation.output}')
    while not observation.done and epochs <= EPOCHS:
        print(f'\n=== Step {epochs} ===')

        # Agent step
        if epochs == 1:  # Assign as observation the sub-task provided by the user
            agent_out = agent.step(agent.task)
        else:  # Assign as observation the observation produced by the environment
            agent_out = agent.step(observation.output)

        # If the agent decides the sub-task ended, then reset the agent providing
        # a new sub-task and provide the produced report as observation
        if agent_out.__class__ != ReActChain:
            agent.reset()
            agent_out = agent.step(agent_out.task_report)

        # Environment step
        action = Action(agent_out.action)
        observation = driver.step(action)
        print(f'Observation: {observation.output}')

        # Evaluate the current step
        step = f'Action:{agent_out.action}\nObservation: {observation.output}'
        evaluator.evaluate_step(step)

        epochs += 1
    agent.agent_finish(observation.output)
