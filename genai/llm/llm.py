import time
import instructor
from openai import OpenAI
import google.generativeai as GoogleAI
from ..procedures import BaseProcedure


class LLMClient():
    """A client for interacting with various Large Language Models (LLMs).

    This class provides a unified interface for working with different LLM providers,
    currently supporting OpenAI's GPT models and Google's Gemini models.

    Args:
        api_key (str): The third party API key for authentication
        model (str): The name of the LLM to use.

    Attributes:
        client (instructor.client.Instructor): The instructor-based LLM client.
        model (str): The name of the LLM being used.

    Methods:
        invoke(response_model, system_prompt, messages): Invokes the LLM with 
            the given parameters.
    """

    def __init__(self, api_key: str, model: str):
        # Use OpenAI LLM
        if 'gpt' in model:
            self.client = instructor.from_openai(
                OpenAI(api_key=api_key),
                temperature=0,
                seed=0
            )
        # Use Gemini LLM
        elif 'gemini' in model:
            self.client = instructor.from_gemini(
                client=GoogleAI.GenerativeModel(
                    model_name=f"models/{model}",
                ),
                mode=instructor.Mode.GEMINI_JSON,
            )
        self.model = model

    def invoke(self, response_model: BaseProcedure, system_prompt: str, messages: list = []):
        """Invokes the LLM with the given parameters.

        This method formats the prompt, sends it to the appropriate LLM,
        and returns the model's response.

        Args:
            response_model (BaseProcedure): The expected response model structure.
            system_prompt (str): The system prompt to guide the LLM's behavior.
            messages (list, optional): A list of message dictionaries to include 
                in the conversation. Defaults to [].

        Returns:
            pydantic.BaseModel: The response model formatted by the LLM 
        """
        # Invoke OpenAI GPT LLMs
        if 'gpt' in self.model:
            # Format the prompt
            prompt = [{'role': 'system', 'content': system_prompt}]
            prompt += messages

            # Invoke the LLM
            llm_out = self.client.chat.completions.create(
                model=self.model,
                response_model=response_model,
                messages=prompt,
                max_retries=5
            )

        # Invoke Gemini LLMs
        elif 'gemini' in self.model:
            # Format the prompt
            prompt += [{'role': 'user', 'content': 'Execution:'}]

            time.sleep(5)  # Wait 5 seconds to respect the request limits

            # Invoke the LLM
            llm_out = self.client.messages.create(
                response_model=response_model,
                messages=prompt
            )

        return llm_out
